#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de inÃ­cio rÃ¡pido - converte seu randomforest.py atual para a nova estrutura.

INSTRUÃ‡Ã•ES:
1. Coloque seu dataset CSV em data/raw/
2. Modifique as variÃ¡veis abaixo com seus dados reais
3. Execute: python quick_start.py
"""

import sys
from pathlib import Path
import numpy as np

# Adicionar src ao path
sys.path.append(str(Path(__file__).parent / 'src'))

from data.data_loader import DataLoader
from data.preprocessing import DataPreprocessor
from models.random_forest import RandomForestModel
from utils.logger import setup_logger


# ==========================================
# ğŸ”§ CONFIGURAÃ‡Ã•ES - MODIFIQUE AQUI
# ==========================================

# Nome do seu arquivo de dados (deve estar em data/raw/)
DATASET_FILENAME = "seu_dataset.csv"  # â† MODIFIQUE AQUI

# Nome da coluna target (a que vocÃª quer prever)
TARGET_COLUMN = "target"  # â† MODIFIQUE AQUI

# Tipo de problema ('classification' ou 'regression')
TASK_TYPE = "classification"  # â† MODIFIQUE AQUI

# ProporÃ§Ã£o para teste (20% Ã© padrÃ£o)
TEST_SIZE = 0.2

# Se deve fazer busca de hiperparÃ¢metros (True/False)
TUNE_HYPERPARAMS = True

# ==========================================


def main():
    """ConversÃ£o automÃ¡tica do seu cÃ³digo."""
    
    # Setup inicial
    logger = setup_logger(name='quick_start', level='INFO')
    
    print("ğŸŒ² QUICK START - Random Forest ML Project")
    print("=" * 50)
    
    try:
        # ===== 1. VERIFICAR SE DATASET EXISTE =====
        data_path = Path("data/raw") / DATASET_FILENAME
        
        if not data_path.exists():
            print(f"âŒ Erro: Dataset nÃ£o encontrado em {data_path}")
            print("\nğŸ“‹ INSTRUÃ‡Ã•ES:")
            print("1. Coloque seu arquivo CSV em data/raw/")
            print("2. Modifique DATASET_FILENAME no inÃ­cio deste script")
            print("3. Execute novamente: python quick_start.py")
            return False
            
        print(f"âœ… Dataset encontrado: {data_path}")
        
        # ===== 2. CARREGAR E VALIDAR DADOS =====
        logger.info("Carregando dados")
        data_loader = DataLoader()
        df = data_loader.load_csv(DATASET_FILENAME)
        
        # Mostrar info bÃ¡sica
        print(f"ğŸ“Š Dataset: {df.shape[0]} linhas, {df.shape[1]} colunas")
        print(f"ğŸ“‹ Colunas: {list(df.columns)}")
        
        # Verificar se target existe
        if TARGET_COLUMN not in df.columns:
            print(f"âŒ Erro: Coluna target '{TARGET_COLUMN}' nÃ£o encontrada")
            print(f"ğŸ“‹ Colunas disponÃ­veis: {list(df.columns)}")
            print("ğŸ’¡ Modifique TARGET_COLUMN no inÃ­cio do script")
            return False
            
        print(f"âœ… Coluna target encontrada: {TARGET_COLUMN}")
        
        # ===== 3. PRÃ‰-PROCESSAMENTO AUTOMÃTICO =====
        logger.info("Iniciando prÃ©-processamento automÃ¡tico")
        preprocessor = DataPreprocessor()
        
        X_train, X_test, y_train, y_test = preprocessor.preprocess_pipeline(
            df=df,
            target_column=TARGET_COLUMN,
            missing_strategy='mean',
            encoding_type='onehot',
            scale_features=True,
            test_size=TEST_SIZE
        )
        
        print(f"âœ… PrÃ©-processamento concluÃ­do:")
        print(f"   ğŸ“ˆ Treino: {X_train.shape[0]} amostras, {X_train.shape[1]} features")
        print(f"   ğŸ“Š Teste: {X_test.shape[0]} amostras")
        
        # ===== 4. TREINAMENTO DO MODELO =====
        logger.info("Criando modelo Random Forest")
        model = RandomForestModel(
            task_type=TASK_TYPE,
            n_estimators=100,
            random_state=42
        )
        
        if TUNE_HYPERPARAMS:
            print("ğŸ” Buscando melhores hiperparÃ¢metros...")
            tuning_results = model.hyperparameter_tuning(X_train, y_train)
            print(f"âœ… Melhores parÃ¢metros: {tuning_results['best_params']}")
        else:
            print("ğŸš€ Treinando modelo com parÃ¢metros padrÃ£o...")
            model.train(X_train, y_train)
        
        # ===== 5. AVALIAÃ‡ÃƒO COMPLETA =====
        logger.info("Avaliando modelo")
        metrics = model.evaluate(X_test, y_test)
        cv_results = model.cross_validate(X_train, y_train)
        
        # Exibir resultados
        print("\nğŸ“Š RESULTADOS DA AVALIAÃ‡ÃƒO:")
        print("-" * 30)
        
        if TASK_TYPE == 'classification':
            print(f"ğŸ¯ AcurÃ¡cia: {metrics['accuracy']:.4f}")
            print(f"ğŸ“ PrecisÃ£o: {metrics['precision']:.4f}")
            print(f"ğŸ” Recall: {metrics['recall']:.4f}")
            print(f"âš–ï¸ F1-Score: {metrics['f1']:.4f}")
            if 'roc_auc' in metrics:
                print(f"ğŸ“ˆ ROC-AUC: {metrics['roc_auc']:.4f}")
        else:
            print(f"ğŸ“Š RÂ² Score: {metrics['r2']:.4f}")
            print(f"ğŸ“ RMSE: {metrics['rmse']:.4f}")
            print(f"ğŸ“ MAE: {metrics['mae']:.4f}")
            
        print(f"âœ… ValidaÃ§Ã£o Cruzada: {cv_results['mean_score']:.4f} Â± {cv_results['std_score']*2:.4f}")
        
        # ===== 6. FEATURE IMPORTANCE =====
        top_features = model.get_feature_importance(top_n=10)
        print("\nğŸ¯ TOP 10 FEATURES MAIS IMPORTANTES:")
        print("-" * 40)
        for i, (_, row) in enumerate(top_features.iterrows(), 1):
            print(f"{i:2d}. {row['feature']:<20} {row['importance']:.4f}")
        
        # ===== 7. SALVAR TUDO =====
        logger.info("Salvando modelo e resultados")
        Path("data/models").mkdir(parents=True, exist_ok=True)
        
        # Salvar modelo e preprocessador
        model_path = f"data/models/random_forest_{TASK_TYPE}.joblib"
        preprocessor_path = f"data/models/preprocessor_{TASK_TYPE}.joblib"
        
        model.save_model(model_path)
        preprocessor.save_preprocessors(preprocessor_path)
        
        # Salvar mÃ©tricas
        import json
        metrics_data = {
            **{k: v for k, v in metrics.items() if k not in ['classification_report']},
            'cv_results': cv_results,
            'feature_importance': top_features.to_dict('records')
        }
        
        if TUNE_HYPERPARAMS:
            metrics_data['best_params'] = tuning_results['best_params']
        
        # Converter numpy arrays para listas
        for key, value in metrics_data.items():
            if isinstance(value, np.ndarray):
                metrics_data[key] = value.tolist()
        
        metrics_path = f"data/models/metrics_{TASK_TYPE}.json"
        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(metrics_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ARQUIVOS SALVOS:")
        print(f"   ğŸ¤– Modelo: {model_path}")
        print(f"   ğŸ”§ Preprocessador: {preprocessor_path}")
        print(f"   ğŸ“Š MÃ©tricas: {metrics_path}")
        
        # ===== 8. INSTRUÃ‡Ã•ES FINAIS =====
        print("\n" + "="*50)
        print("ğŸ‰ CONVERSÃƒO CONCLUÃDA COM SUCESSO!")
        print("="*50)
        
        print("\nğŸš€ PRÃ“XIMOS PASSOS:")
        print("1. Execute o dashboard:")
        print("   python scripts/run_dashboard.py")
        print("\n2. Ou com Docker:")
        print("   docker-compose up --build")
        print("\n3. Acesse: http://localhost:8501")
        
        print("\nğŸ’¡ DICAS:")
        print("â€¢ Use o modo 'Modelo Treinado' para ver todas as mÃ©tricas")
        print("â€¢ Use o modo 'PrediÃ§Ãµes' para fazer novas prediÃ§Ãµes")
        print("â€¢ Seus arquivos estÃ£o salvos em data/models/")
        
        return True
        
    except Exception as e:
        logger.error(f"Erro durante conversÃ£o: {str(e)}")
        print(f"\nâŒ ERRO: {str(e)}")
        print("\nğŸ”§ POSSÃVEIS SOLUÃ‡Ã•ES:")
        print("1. Verifique se o dataset estÃ¡ em data/raw/")
        print("2. Confirme o nome da coluna target")
        print("3. Verifique se nÃ£o hÃ¡ valores incompatÃ­veis nos dados")
        return False


if __name__ == "__main__":
    # Executar conversÃ£o
    success = main()
    
    if not success:
        print("\nğŸ“‹ CHECKLIST DE PROBLEMAS COMUNS:")
        print("â–¡ Dataset estÃ¡ em data/raw/?")
        print("â–¡ Nome do arquivo estÃ¡ correto?")
        print("â–¡ Coluna target existe?")
        print("â–¡ Dados tÃªm formato correto?")
        print("â–¡ DependÃªncias instaladas? (pip install -r requirements.txt)")
