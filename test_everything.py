#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ§ª TESTE COMPLETO - Valida toda a estrutura e gera exemplo funcional.

Execute este script para testar se tudo estÃ¡ funcionando corretamente.
"""

import sys
import os
from pathlib import Path
import traceback


def setup_project_structure():
    """Cria estrutura completa do projeto."""
    
    print("ğŸ“ Criando estrutura de diretÃ³rios...")
    
    directories = [
        'data/raw', 'data/processed', 'data/models',
        'src/data', 'src/models', 'src/utils', 'src/dashboard',
        'scripts', 'tests', 'logs', 'configs'
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
    
    # Criar __init__.py files
    init_dirs = ['src', 'src/data', 'src/models', 'src/utils', 'src/dashboard', 'tests']
    for directory in init_dirs:
        (Path(directory) / '__init__.py').touch()
    
    print("âœ… Estrutura criada")


def test_imports():
    """Testa se todas as importaÃ§Ãµes funcionam."""
    
    print("ğŸ“¦ Testando importaÃ§Ãµes...")
    
    try:
        # Adicionar src ao path
        sys.path.append(str(Path(__file__).parent / 'src'))
        
        # Testar importaÃ§Ãµes bÃ¡sicas
        import pandas as pd
        import numpy as np
        from sklearn.ensemble import RandomForestClassifier
        
        print("âœ… Bibliotecas bÃ¡sicas OK")
        
        # Testar importaÃ§Ãµes do projeto
        from data.data_loader import DataLoader
        from data.preprocessing import DataPreprocessor  
        from models.random_forest import RandomForestModel
        from utils.logger import setup_logger
        
        print("âœ… MÃ³dulos do projeto OK")
        return True
        
    except Exception as e:
        print(f"âŒ Erro nas importaÃ§Ãµes: {e}")
        print("ğŸ’¡ Execute: pip install -r requirements.txt")
        return False


def create_sample_dataset():
    """Cria dataset de exemplo para teste."""
    
    print("ğŸ“Š Criando dataset de exemplo...")
    
    import pandas as pd
    import numpy as np
    
    np.random.seed(42)
    n_samples = 500
    
    # Dataset Titanic-like para classificaÃ§Ã£o
    df = pd.DataFrame({
        'idade': np.random.randint(1, 80, n_samples),
        'tarifa': np.random.uniform(7, 500, n_samples),
        'classe': np.random.choice([1, 2, 3], n_samples),
        'sexo': np.random.choice(['masculino', 'feminino'], n_samples),
        'embarcou': np.random.choice(['C', 'Q', 'S'], n_samples),
        'familia_size': np.random.randint(0, 8, n_samples),
        'sobreviveu': np.random.choice([0, 1], n_samples, p=[0.4, 0.6])
    })
    
    # Adicionar alguns valores missing
    missing_idx = np.random.choice(df.index, size=20, replace=False)
    df.loc[missing_idx[:10], 'idade'] = np.nan
    df.loc[missing_idx[10:], 'tarifa'] = np.nan
    
    # Salvar dataset
    df.to_csv('data/raw/titanic_exemplo.csv', index=False)
    
    print(f"âœ… Dataset criado: {df.shape[0]} linhas, {df.shape[1]} colunas")
    print("ğŸ“ Salvo em: data/raw/titanic_exemplo.csv")
    
    return df


def test_full_pipeline():
    """Testa pipeline completo de ML."""
    
    print("ğŸ”¬ Testando pipeline completo...")
    
    try:
        # ImportaÃ§Ãµes
        sys.path.append(str(Path(__file__).parent / 'src'))
        from data.data_loader import DataLoader
        from data.preprocessing import DataPreprocessor
        from models.random_forest import RandomForestModel
        from utils.logger import setup_logger
        
        # Setup logger
        logger = setup_logger(name='test', level='INFO', log_file='logs/test.log')
        
        # 1. Carregar dados
        data_loader = DataLoader()
        df = data_loader.load_csv('titanic_exemplo.csv')
        print(f"âœ… Dados carregados: {df.shape}")
        
        # 2. PrÃ©-processamento
        preprocessor = DataPreprocessor()
        X_train, X_test, y_train, y_test = preprocessor.preprocess_pipeline(
            df=df,
            target_column='sobreviveu',
            test_size=0.2
        )
        print(f"âœ… PrÃ©-processamento: {X_train.shape[1]} features")
        
        # 3. Treinamento
        model = RandomForestModel(task_type='classification', n_estimators=50)
        model.train(X_train, y_train)
        print("âœ… Modelo treinado")
        
        # 4. AvaliaÃ§Ã£o
        metrics = model.evaluate(X_test, y_test)
        print(f"âœ… AcurÃ¡cia: {metrics['accuracy']:.3f}")
        
        # 5. Salvar
        model.save_model('data/models/test_model.joblib')
        preprocessor.save_preprocessors('data/models/test_preprocessor.joblib')
        print("âœ… Modelo salvo")
        
        # 6. Testar prediÃ§Ã£o
        prediction = model.predict(X_test[:5])
        print(f"âœ… PrediÃ§Ãµes: {prediction}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro no pipeline: {e}")
        traceback.print_exc()
        return False


def test_dashboard_files():
    """Verifica se arquivos do dashboard existem."""
    
    print("ğŸ¨ Verificando dashboard...")
    
    dashboard_file = Path('src/dashboard/streamlit_app.py')
    if dashboard_file.exists():
        print("âœ… Dashboard encontrado")
        print("ğŸš€ Para executar: streamlit run src/dashboard/streamlit_app.py")
        return True
    else:
        print("âŒ Dashboard nÃ£o encontrado")
        return False


def test_docker():
    """Verifica se Docker pode ser construÃ­do."""
    
    print("ğŸ³ Verificando Docker...")
    
    dockerfile = Path('Dockerfile')
    compose_file = Path('docker-compose.yml')
    
    if dockerfile.exists() and compose_file.exists():
        print("âœ… Arquivos Docker encontrados")
        print("ğŸš€ Para executar: docker-compose up --build")
        return True
    else:
        print("âŒ Arquivos Docker nÃ£o encontrados")
        return False


def create_run_instructions():
    """Cria arquivo com instruÃ§Ãµes de execuÃ§Ã£o."""
    
    instructions = """# ğŸš€ INSTRUÃ‡Ã•ES DE EXECUÃ‡ÃƒO

## âœ… Teste ConcluÃ­do com Sucesso!

### ğŸ¯ PrÃ³ximos Passos:

#### 1. ğŸ“Š Usar com seus prÃ³prios dados:
```bash
# Coloque seu CSV em data/raw/
cp seu_dataset.csv data/raw/

# Treine o modelo
python scripts/train_model.py --data data/raw/seu_dataset.csv --target sua_coluna_target --tune-hyperparams
```

#### 2. ğŸ“± Executar Dashboard:
```bash
# OpÃ§Ã£o 1: Streamlit direto
streamlit run src/dashboard/streamlit_app.py

# OpÃ§Ã£o 2: Script helper
python scripts/run_dashboard.py

# OpÃ§Ã£o 3: Docker
docker-compose up --build
```

#### 3. ğŸ§ª Executar Testes:
```bash
pytest tests/ -v
```

#### 4. ğŸ”§ Desenvolvimento:
```bash
# Instalar dependÃªncias de desenvolvimento
pip install -r requirements.txt

# Formatar cÃ³digo
black .

# Linting
flake8 .
```

### ğŸ“ Estrutura dos Arquivos Gerados:

- `data/raw/titanic_exemplo.csv` - Dataset de exemplo
- `data/models/test_model.joblib` - Modelo treinado
- `data/models/test_preprocessor.joblib` - Preprocessador
- `logs/test.log` - Logs de execuÃ§Ã£o

### ğŸ’¡ Dicas:

1. **Dados Reais**: Substitua o dataset de exemplo pelos seus dados
2. **CustomizaÃ§Ã£o**: Modifique parÃ¢metros nos arquivos de configuraÃ§Ã£o
3. **Deploy**: Use Streamlit Cloud para deploy gratuito
4. **CI/CD**: GitHub Actions jÃ¡ configurado

### ğŸ†˜ Problemas Comuns:

- **Erro de importaÃ§Ã£o**: Execute `pip install -r requirements.txt`
- **Streamlit nÃ£o inicia**: Verifique se porta 8501 estÃ¡ livre
- **Docker nÃ£o builda**: Verifique se Docker estÃ¡ instalado

### ğŸŠ ParabÃ©ns!

Sua estrutura de ML estÃ¡ pronta para produÃ§Ã£o!
"""

    with open('INSTRUCOES.md', 'w', encoding='utf-8') as f:
        f.write(instructions)
    
    print("âœ… InstruÃ§Ãµes salvas em INSTRUCOES.md")


def main():
    """FunÃ§Ã£o principal de teste."""
    
    print("ğŸ§ª TESTE COMPLETO DA ESTRUTURA ML")
    print("="*50)
    
    all_tests_passed = True
    
    try:
        # 1. Criar estrutura
        setup_project_structure()
        
        # 2. Testar importaÃ§Ãµes
        if not test_imports():
            all_tests_passed = False
            
        # 3. Criar dados de exemplo
        create_sample_dataset()
        
        # 4. Testar pipeline completo
        if not test_full_pipeline():
            all_tests_passed = False
            
        # 5. Verificar dashboard
        test_dashboard_files()
        
        # 6. Verificar Docker
        test_docker()
        
        # 7. Criar instruÃ§Ãµes
        create_run_instructions()
        
        print("\n" + "="*50)
        
        if all_tests_passed:
            print("ğŸ‰ TODOS OS TESTES PASSARAM!")
            print("âœ… Estrutura ML pronta para uso")
            print("\nğŸš€ EXECUTE AGORA:")
            print("streamlit run src/dashboard/streamlit_app.py")
            print("\nğŸ“– Veja INSTRUCOES.md para mais detalhes")
        else:
            print("âš ï¸ ALGUNS TESTES FALHARAM")
            print("ğŸ”§ Verifique os erros acima e:")
            print("1. Execute: pip install -r requirements.txt") 
            print("2. Execute novamente: python test_everything.py")
            
    except Exception as e:
        print(f"âŒ ERRO CRÃTICO: {e}")
        traceback.print_exc()
        
        print("\nğŸ†˜ SOLUÃ‡ÃƒO RÃPIDA:")
        print("1. Verifique se estÃ¡ no diretÃ³rio correto")
        print("2. Execute: pip install pandas numpy scikit-learn streamlit")
        print("3. Execute novamente: python test_everything.py")


if __name__ == "__main__":
    main()
